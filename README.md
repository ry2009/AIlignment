# Control Dataset Project

## Overview
This project aims to create a high-quality dataset of complex control settings for AI alignment research. Each setting consists of a moderately complex environment where an AI agent must balance a main task while potentially pursuing a covert side task, all while being monitored.

## Project Goals
1. Create 3-7 well-designed control environments
2. Implement robust monitoring systems for each environment
3. Validate environments with both human and LLM participants
4. Document and publish findings for the AI safety community

## Repository Structure
- `/environments` - Individual control environments
- `/monitoring` - Monitoring system implementations
- `/docs` - Project documentation
- `/tests` - Validation tests and results
- `project_plan.md` - Detailed project planning
- `progress.md` - Track ongoing progress
- `debug_log.md` - Record debugging attempts and solutions

## Getting Started
[To be added as we implement the environments]

## Safety Notice
This project is intended for AI alignment research purposes only. All findings and implementations should be used responsibly and in accordance with ethical AI development practices. 
